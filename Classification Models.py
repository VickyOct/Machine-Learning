# -*- coding: utf-8 -*-
"""787.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UU_ELe4x_TyL-hVvAOvmcS_RdJw295Vc
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
#Import file
df = pd.read_csv('/content/data.csv')
df.head()

# Grouped by 'Gender'
df.groupby('Gender').count()

# Find rows where Gender is 'Other'
rows_to_remove = df[df['Gender'] == 'Other'].index
# Remove rows where Gender is 'Other'
df = df.drop(index=rows_to_remove)
df.groupby('Gender').count()

df.columns.values

#Check if N/A value is included in the dataset
df.isnull().values.any()

#Remove all N/A values
df = df.dropna()

#Check if N/A values are removed
df.isnull().values.any()

from sklearn.preprocessing import LabelEncoder
#Encode text data into numeric valuesâ€º
label_encoder = LabelEncoder()
#Encode gender label
gender_cat = df['Gender']
gender_encoded = label_encoder.fit_transform(gender_cat)
gender_frame = pd.DataFrame(gender_encoded, columns = ['Gender'])
gender_frame

gender_frame.groupby('Gender').count()

gender_frame.isnull().values.any()

#Replace encoded value into the dataframe
df['Gender'] = gender_frame.values

df.isnull().values.any()

df.head()

#Encode Education Level and replace the corresponding column in the dataframe
education_level_encoded = df['Education Level']
education_level_encoded = label_encoder.fit_transform(education_level_encoded)
education_level_frame = pd.DataFrame(education_level_encoded, columns = ['Education Level'])
print(education_level_frame.head)
df['Education Level'] = education_level_frame.values

#Encode Job Title and replace the corresponding column in the dataframe
job_encode = df['Job Title']
job_encode = label_encoder.fit_transform(job_encode)
job_encode = pd.DataFrame(job_encode, columns = ['Job Title'])
print(job_encode.head)
df['Job Title'] = job_encode.values

#Encode Country and replace the corresponding column in the dataframe
c_encode = df['Country']
c_encode = label_encoder.fit_transform(c_encode)
c_encode = pd.DataFrame(c_encode, columns = ['Country'])
print(c_encode.head)
df['Country'] = c_encode.values


#Encode Race and replace the corresponding column in the dataframe
race_encode = df['Race']
race_encode = label_encoder.fit_transform(race_encode)
race_encode = pd.DataFrame(race_encode, columns = ['Race'])
print(race_encode.head)
df['Race'] = race_encode.values

#Cleaned dataset
df.head()

df.isnull().values.any()

y = df["Gender"]

x = df
del x["Gender"]
del x['Unnamed: 0']
x.head()

print(x.shape)

from sklearn.model_selection import train_test_split
#Split into train and test set
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)
print(x_train.shape)
print(x_test.shape)

# Find columns with N/A values
columns_with_na = x_train.columns[x_train.isna().any()].tolist()
print("Columns with N/A values:", columns_with_na)

import time
from datetime import timedelta
from sklearn.neighbors import KNeighborsClassifier
from sklearn import metrics
from sklearn.metrics import f1_score
from sklearn.metrics import confusion_matrix, roc_curve, ConfusionMatrixDisplay
from sklearn.model_selection import GridSearchCV

#Use KNN as classifier
start_time = time.time()
classifier =  KNeighborsClassifier(n_neighbors= 35)

classifier.fit(x_train, y_train)
end_time = time.time()
print("K Nearest Neighbors Training time used:", end_time - start_time)

start_time = time.time()
y_pred = classifier.predict(x_test)
end_time = time.time()
print("K Nearest Neighbors Testing time used:",  end_time - start_time)
#Confusion matrix and evaluation result
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
accu_knn = metrics.accuracy_score(y_pred,y_test)
print("Accuracy of KNN:", accu_knn)
fs_knn = f1_score(y_test, y_pred,average = 'macro')
print("F1 score for KNN:",fs_knn)
print("CM for KNeighborsClassifier: ")
disp.plot()
plt.show()

import time
from datetime import timedelta
from sklearn.neighbors import KNeighborsClassifier
from sklearn import metrics
from sklearn.metrics import f1_score
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc
from sklearn.model_selection import GridSearchCV

#Use KNN as classifier with cross validation for parameter selection
knn_param_grid = {'n_neighbors': [3, 5, 7, 9]}  # Example values, can adjust this
knn_classifier = KNeighborsClassifier()
knn_grid = GridSearchCV(knn_classifier, knn_param_grid, cv=5)
start_train_time = time.time()
knn_grid.fit(x_train, y_train)
end_train_time = time.time()
print("K Nearest Neighbors Training time used:", end_train_time - start_train_time)
knn_best_params = knn_grid.best_params_
print("K Nearest Neighbors Best Parameter:", knn_best_params)

knn_classifier = KNeighborsClassifier(n_neighbors=knn_best_params['n_neighbors'])
knn_classifier.fit(x_train, y_train)

start_test_time = time.time()
y_pred = knn_classifier.predict(x_test)
end_test_time = time.time()
print("K Nearest Neighbors Testing time used:", end_test_time - start_test_time)

#Confusion matrix and evaluation result
knn_cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=knn_cm)
accu_knn = metrics.accuracy_score(y_pred,y_test)
print("Accuracy of KNN:", accu_knn)
fs_knn = f1_score(y_test, y_pred,average = 'macro')
print("F1 score for KNN:",fs_knn)
print("CM for KNeighborsClassifier: ")
disp.plot()
plt.show()

#Remove the Job Title column to check whether the performance can be improved
x_remove_job = x_train.drop(columns=["Job Title"])
x_test_remove_job = x_test.drop(columns=["Job Title"])

x_test_remove_job.head()

start_time = time.time()
classifier =  KNeighborsClassifier(n_neighbors= 35)

classifier.fit(x_remove_job, y_train)
end_time = time.time()
print("K Nearest Neighbors Training time used:", end_time - start_time)

start_time = time.time()
y_pred = classifier.predict(x_test_remove_job)
end_time = time.time()
print("K Nearest Neighbors Testing time used:",  end_time - start_time)
#As shown by the result, the performance is worse than applying KNN on the original dataset
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
accu_knn = metrics.accuracy_score(y_pred,y_test)
print("Accuracy of KNN:", accu_knn)
fs_knn = f1_score(y_test, y_pred,average = 'macro')
print("F1 score for KNN:",fs_knn)
print("CM for KNeighborsClassifier: ")
disp.plot()
plt.show()

# ROC curve for KNN
knn_probs = knn_classifier.predict_proba(x_test)
knn_probs = knn_probs[:, 1]
fpr_knn, tpr_knn, _ = roc_curve(y_test, knn_probs)
roc_auc_knn = auc(fpr_knn, tpr_knn)
plt.figure()
plt.plot(fpr_knn, tpr_knn, color='darkorange', lw=2, label='KNN (AUC = {:.2f})'.format(roc_auc_knn))
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend(loc="lower right")
plt.show()

from sklearn.tree import DecisionTreeClassifier
from sklearn.tree import export_text
#Use Decision Tree as classifier
decision_tree = DecisionTreeClassifier(random_state=0, max_depth=8)
start_time = time.time()
decision_tree = decision_tree.fit(x_train, y_train)
end_time = time.time()
print("DcisionTree Training time used:", end_time - start_time)
#Show decision tree
feature_names = x_train.columns.tolist()
r = export_text(decision_tree, feature_names= feature_names)
print(r)

start_time = time.time()
y_pred = decision_tree.predict(x_test)
end_time = time.time()
print("DcisionTree Testing time used:",  end_time - start_time)
#Confusion matrix and evaluation result
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
accu = metrics.accuracy_score(y_pred,y_test)
print("Accuracy of Decision Tree:", accu)
fs = f1_score(y_test, y_pred,average = 'macro')
print("F1 score for Decision Tree:",fs)
print("CM for KNeighborsClassifier: ")
disp.plot()
plt.show()

from sklearn.naive_bayes import GaussianNB
#Use Gaussian Naive Bayes (NB) as classifier
start_time = time.time()
nb_classifier = GaussianNB()
nb_classifier.fit(x_train, y_train)
end_time = time.time()
print("Naive Bayes Traning time used:", end_time - start_time)
start_time = time.time()
y_pred = nb_classifier.predict(x_test)
end_time = time.time()
print("Naive Bayes Testing time used:", end_time - start_time)

#Confusion matrix and evaluation result
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
accu = metrics.accuracy_score(y_pred,y_test)
print("Accuracy of Gaussian Naive Bayes (NB):", accu)
fs = f1_score(y_test, y_pred,average = 'macro')
print("F1 score for Gaussian Naive Bayes (NB):",fs)
print("Gaussian Naive Bayes (NB): ")
disp.plot()
plt.show()
print('\n')

#ROC curve for NB and plot ROC
nb_probs = nb_classifier.predict_proba(x_test)
nb_probs = nb_probs[:, 1]
fpr_nb, tpr_nb, _ = roc_curve(y_test, nb_probs)
roc_auc_nb = auc(fpr_nb, tpr_nb)
plt.figure()
plt.plot(fpr_nb, tpr_nb, color='darkorange', lw=2, label='Naive Bayes (AUC = {:.2f})'.format(roc_auc_nb))
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend(loc="lower right")
plt.show()